{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to Pandas** #\n",
        "**Pandas** is an open-source Python library primarily used for **data manipulation and analysis**. It provides data structures and functions that make it easy to work with structured data, particularly **data in the form of tables**.  \n",
        "Pandas is widely used in data science, machine learning, and data analysis because of its powerful and easy-to-use data structures, Series and DataFrame.\n",
        "\n",
        "\n",
        "###**Key Data Structures in Pandas:**###\n",
        "\n",
        "1. **Series:** A one-dimensional array-like object containing a sequence of values.\n",
        "Each value is associated with an index label.\n",
        "2. **DataFrame:** A two-dimensional labeled data structure with columns that can hold different data types.\n",
        "\n",
        "**Common Data Analysis Tasks with Pandas:**\n",
        "\n",
        "1. **Data Import/Export:** Reading data from various file formats (CSV, Excel, JSON, etc.) and writing data to different formats.\n",
        "2. **Data Cleaning:** Handling missing values, removing duplicates, and correcting inconsistencies.\n",
        "3. **Data Manipulation:** Filtering, sorting, grouping, and transforming data.\n",
        "4. **Data Analysis:** Statistical calculations, time series analysis, and exploratory data analysis.\n",
        "5. **Data Visualization:** Creating informative visualizations using libraries like Matplotlib and Seaborn.\n",
        "\n",
        "**Installing Pandas:**\n",
        "To use pandas, you need to install it using pip:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "pip install pandas\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "fO6xyk_oJXYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Basic Examples**##\n",
        "1. **Importing Pandas**"
      ],
      "metadata": {
        "id": "mEDMFKqkL6KR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ckEJ5QpJT7U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Creating a Series**"
      ],
      "metadata": {
        "id": "hAAkBD4wMGBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a simple Series\n",
        "data = pd.Series([1, 2, 3, 4, 5])\n",
        "print(data)"
      ],
      "metadata": {
        "id": "XYCOoytLMK_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Creating a DataFrame**\n",
        "The DataFrame is like a table with rows and columns."
      ],
      "metadata": {
        "id": "f48r9v_uMQkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a DataFrame from a dictionary\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Age': [24, 27, 22],\n",
        "    'City': ['New York', 'San Francisco', 'Los Angeles']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "EHyEU9SqMUbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Reading a CSV File**"
      ],
      "metadata": {
        "id": "ahHeHHxcMaUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data.csv\")\n",
        "print(df.head())  # Display the first few rows of the DataFrame\n"
      ],
      "metadata": {
        "id": "jU5DIDZ8MeFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Data Filtering and Manipulation**"
      ],
      "metadata": {
        "id": "azVwLHaQMhzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting rows where age > 23\n",
        "filtered_df = df[df['Age'] > 23]\n",
        "print(filtered_df)\n"
      ],
      "metadata": {
        "id": "njEDW8XdMk00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## READING OUR TEST FILE ##"
      ],
      "metadata": {
        "id": "z3dvhj0E0pDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a Pandas DataFrame\n",
        "file_name = \"Dataset_Lab_Test.csv\"  # File name\n",
        "data = pd.read_csv(file_name)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "XYwE-6HG0tEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the dataset has no header, use the header=None parameter and assign column names manually:\n",
        "\n",
        "```\n",
        "data = pd.read_csv(file_name, header=None, names=['Year', 'Month', 'Region', 'Product_A', 'Product_B', 'Product_C'])\n",
        "```"
      ],
      "metadata": {
        "id": "TmNWl4vA03JE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate MEAN, STANDARD DEVIATION, VARIANCE, MEDIAN, MODE ###"
      ],
      "metadata": {
        "id": "rfEe-Wg31jUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate statistics for Product_A\n",
        "average = data['Product_A'].mean()\n",
        "std_dev = data['Product_A'].std()\n",
        "variance = data['Product_A'].var()\n",
        "median = data['Product_A'].median()\n",
        "mode = data['Product_A'].mode()\n",
        "\n",
        "# Display the results\n",
        "print(f\"Average (Mean) of Product_A: {average}\")\n",
        "print(f\"Standard Deviation of Product_A: {std_dev}\")\n",
        "print(f\"Variance of Product_A: {variance}\")\n",
        "print(f\"Median of Product_A: {median}\")\n",
        "print(f\"Mode of Product_A: {mode.tolist()}\")"
      ],
      "metadata": {
        "id": "UlD1h3_a1gJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Calculate MEAN grouped by something (year or region)**###\n"
      ],
      "metadata": {
        "id": "hDNFOp5r2HTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'Year' and calculate the average of 'Product_A'\n",
        "average_product_a_by_year = data.groupby('Year')['Product_A'].mean()\n",
        "\n",
        "# Display the result\n",
        "print(average_product_a_by_year)"
      ],
      "metadata": {
        "id": "NRWsCKTL0vSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'Region' and calculate the mean for each product\n",
        "mean_by_region = data.groupby('Region')[['Product_A', 'Product_B', 'Product_C']].mean()\n",
        "\n",
        "# Display the result\n",
        "print(mean_by_region)"
      ],
      "metadata": {
        "id": "LPf9jXKO2yyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA CLEANING WITH PANDAS ###"
      ],
      "metadata": {
        "id": "obp9m3gV2tBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data cleaning is a crucial part of data preprocessing to ensure your dataset is free from errors, inconsistencies, or irrelevant data. Pandas provides powerful tools for cleaning and preparing data for analysis. Below are common data cleaning tasks and how to perform them with Pandas:"
      ],
      "metadata": {
        "id": "WToLr8Ig4AYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**1. Handling Missing Data**###\n",
        "\n",
        "**Check for missing values:**"
      ],
      "metadata": {
        "id": "7fzs8DP64Czd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in each column\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Display rows with missing data\n",
        "print(data[data.isnull().any(axis=1)])\n"
      ],
      "metadata": {
        "id": "ohkdK7Hr3-0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Drop rows or columns with missing values:**"
      ],
      "metadata": {
        "id": "i_xTj3oc4YUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna()  # Removes rows with any missing values\n",
        "data = data.dropna(axis=1)  # Removes columns with any missing values"
      ],
      "metadata": {
        "id": "ASQOaKaS4dcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filling missing values**"
      ],
      "metadata": {
        "id": "uadLloaP5Xbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with a specific value\n",
        "data['Column_Name'] = data['Column_Name'].fillna(0)\n",
        "\n",
        "# Fill with the mean/median/mode\n",
        "data['Column_Name'] = data['Column_Name'].fillna(data['Column_Name'].mean())\n",
        "data['Column_Name'] = data['Column_Name'].fillna(data['Column_Name'].median())\n",
        "data['Column_Name'] = data['Column_Name'].fillna(data['Column_Name'].mode()[0])\n",
        "\n",
        "# Forward/Backward fill\n",
        "data['Column_Name'] = data['Column_Name'].fillna(method='ffill')  # Forward fill\n",
        "data['Column_Name'] = data['Column_Name'].fillna(method='bfill')  # Backward fill\n"
      ],
      "metadata": {
        "id": "QjvN-E-l5eiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**2. Removing Duplicate Rows**###\n",
        "\n",
        "**`Find duplicates:`**"
      ],
      "metadata": {
        "id": "vRjcdvSR4hMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.duplicated())"
      ],
      "metadata": {
        "id": "bBVjyz3G4r7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove duplicates:**"
      ],
      "metadata": {
        "id": "cDbmOXWI4s9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop_duplicates()"
      ],
      "metadata": {
        "id": "ClLYGpZ54yYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**3. Removing Outliers**###\n",
        "\n"
      ],
      "metadata": {
        "id": "at2_bXkp5qSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify outliers using the IQR method\n",
        "Q1 = data['Product_C'].quantile(0.25)\n",
        "Q3 = data['Product_C'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define the lower and upper bounds\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filter out rows with outliers\n",
        "data = data[(data['Product_C'] >= lower_bound) & (data['Product_C'] <= upper_bound)]\n"
      ],
      "metadata": {
        "id": "s0yqUSXM5uNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**4. Convert Data Types**###\n",
        "\n"
      ],
      "metadata": {
        "id": "DRRDa3WD6V7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct data types\n",
        "data['Year'] = data['Year'].astype(int)"
      ],
      "metadata": {
        "id": "GluH7uZ96Tpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**5. Normalize Product A**###\n",
        "\n"
      ],
      "metadata": {
        "id": "cgTeO_v86ZxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize Product_A\n",
        "data['Normalized_Product_A'] = (data['Product_A'] - data['Product_A'].min()) / (data['Product_A'].max() - data['Product_A'].min())\n"
      ],
      "metadata": {
        "id": "2aRxFfvC6mJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**6. Filter Invalid Inputs**###\n",
        "\n"
      ],
      "metadata": {
        "id": "IfYIzTr161JK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows where a column value does not meet a condition\n",
        "data = data[data['Year'] > 2021]  # Keep rows where values are greater than 0\n",
        "data = data[data['Region'].isin(['North', 'South', 'East', 'West'])]  # Keep rows with specific categories\n"
      ],
      "metadata": {
        "id": "icqO3qvZ6zPJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}